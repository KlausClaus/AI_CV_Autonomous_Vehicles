{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import random\n",
    "from torchmetrics import JaccardIndex\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler,random_split, ConcatDataset, Subset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models.segmentation as segmentation\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the random seed\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WildScenesDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None, target_transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.images = sorted(os.listdir(image_dir))\n",
    "      \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.images[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.images[idx])\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")  \n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.target_transform:\n",
    "            mask = self.target_transform(mask)\n",
    "            mask = torch.squeeze(mask, 0).long()\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToLabelTensor:\n",
    "    def __call__(self, pic):\n",
    "        tensor = torch.from_numpy(np.array(pic, dtype=np.int32)).long()\n",
    "        max_value = tensor.max().item()\n",
    "        if max_value >= 19:\n",
    "            print(f\"Label value out of range: {max_value}\")\n",
    "        assert max_value < 19, \"Label value out of range\"  \n",
    "        return tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from multiprocessing import Pool\n",
    "\n",
    "base_paths = [\n",
    "    # '/root/autodl-tmp/K-01/',\n",
    "    # '/root/autodl-tmp/K-03/',\n",
    "    '/root/autodl-tmp/V-01/',\n",
    "    # '/root/autodl-tmp/V-02/',\n",
    "    # '/root/autodl-tmp/V-03/'\n",
    "]\n",
    "image_dirs = [os.path.join(base_path, 'image') for base_path in base_paths]\n",
    "mask_dirs = [os.path.join(base_path, 'indexLabel') for base_path in base_paths]\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((512, 512)),  \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "target_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((512, 512), interpolation=Image.NEAREST),\n",
    "        # transforms.ToTensor(),\n",
    "        ToLabelTensor(),\n",
    "    ]\n",
    ")\n",
    "datasets = [\n",
    "    WildScenesDataset(image_dir=image_dir, mask_dir=mask_dir, transform=transform, target_transform=target_transform)\n",
    "    for image_dir, mask_dir in zip(image_dirs, mask_dirs)\n",
    "]\n",
    "full_dataset = ConcatDataset(datasets)\n",
    "\n",
    "\n",
    "# split the dataset\n",
    "train_size = int(0.7 * len(full_dataset))\n",
    "val_size = int(0.15 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True, num_workers=4, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=10, shuffle=False, num_workers=4, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False, num_workers=4, drop_last=True)\n",
    "\n",
    "\n",
    "\n",
    "class_names = [\n",
    "    \"unlabelled\",\n",
    "    \"asphalt\",\n",
    "    \"dirt\",\n",
    "    \"mud\",\n",
    "    \"water\",\n",
    "    \"gravel\",\n",
    "    \"other-terrain\",\n",
    "    \"tree-trunk\",\n",
    "    \"tree-foliage\",\n",
    "    \"bush\",\n",
    "    \"fence\",\n",
    "    \"structure\",\n",
    "    \"pole\",\n",
    "    \"vehicle\",\n",
    "    \"rock\",\n",
    "    \"log\",\n",
    "    \"other-object\",\n",
    "    \"sky\",\n",
    "    \"grass\",\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# def check_class_distribution(dataset, num_classes):\n",
    "#     class_counts = np.zeros(num_classes)\n",
    "#     for _, mask in dataset:\n",
    "#         mask = mask.numpy().flatten()\n",
    "#         for cls in range(num_classes):\n",
    "#             class_counts[cls] += np.sum(mask == cls)\n",
    "#     return class_counts\n",
    "\n",
    "# class_counts = check_class_distribution(train_dataset, 19)\n",
    "# # print(\"Class distribution in the dataset:\")\n",
    "# # for i, count in enumerate(class_counts):\n",
    "# #     print(f'{class_names[i]}: {count}')\n",
    "\n",
    "# def plot_class_distribution(class_counts, class_names):\n",
    "#     counts = [class_counts[i] for i in range(len(class_names))]\n",
    "#     plt.figure(figsize=(10, 5))\n",
    "#     plt.bar(class_names, counts)\n",
    "#     plt.xlabel('Class')\n",
    "#     plt.ylabel('Number of Pixels')\n",
    "#     plt.title('Class Distribution in Dataset')\n",
    "#     plt.xticks(rotation=90)\n",
    "#     plt.show()\n",
    "\n",
    "# plot_class_distribution(class_counts, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.delta = delta\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.counter = 0\n",
    "\n",
    "    def __call__(self, val_iou, model):\n",
    "        score = val_iou\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, model):\n",
    "        # save model\n",
    "        torch.save(model.state_dict(), 'checkpoint.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet101_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models.segmentation as models\n",
    "\n",
    "# apply pretrained deeplabv3 model\n",
    "num_classes=19\n",
    "model = models.deeplabv3_resnet101(pretrained=True)\n",
    "model.classifier[4] = torch.nn.Conv2d(256, num_classes, kernel_size=(1, 1))\n",
    "\n",
    "# #self-defined classfifier\n",
    "# original_classifier = model.classifier\n",
    "\n",
    "# class CustomClassifier(nn.Sequential):\n",
    "#     def __init__(self, original_classifier, num_classes):\n",
    "#         super(CustomClassifier, self).__init__()\n",
    "#         self.original_classifier = original_classifier\n",
    "\n",
    "#         # new convolution layer\n",
    "#         self.additional_conv = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "#         self.relu = nn.ReLU()\n",
    "\n",
    "#         self.classifier = nn.Conv2d(256, num_classes, kernel_size=(1, 1))\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.original_classifier[0](x)\n",
    "#         x = self.original_classifier[1](x)\n",
    "#         x = self.original_classifier[2](x)\n",
    "#         x = self.original_classifier[3](x)\n",
    "#         x = self.relu(self.additional_conv(x))\n",
    "#         x = self.classifier(x)\n",
    "#         return x\n",
    "\n",
    "# model.classifier = CustomClassifier(original_classifier, num_classes)\n",
    "\n",
    "\n",
    "\n",
    "iou_metric = JaccardIndex(task='multiclass', num_classes=num_classes, average=None).to('cuda')\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "# class DiceLoss(nn.Module):\n",
    "#     def __init__(self, smooth=1.e-5):\n",
    "#         super(DiceLoss, self).__init__()\n",
    "#         self.smooth = smooth\n",
    "\n",
    "#     def forward(self, outputs, targets):\n",
    "#         outputs = torch.softmax(outputs, dim=1) \n",
    "#         targets = F.one_hot(targets, num_classes=outputs.shape[1]).permute(0, 3, 1, 2).float()\n",
    "\n",
    "#         intersection = torch.sum(outputs * targets, dim=(2, 3))\n",
    "#         union = torch.sum(outputs, dim=(2, 3)) + torch.sum(targets, dim=(2, 3))\n",
    "\n",
    "#         dice_score = (2. * intersection + self.smooth) / (union + self.smooth)\n",
    "#         dice_loss = 1 - dice_score.mean(dim=1)\n",
    "#         return dice_loss.mean()\n",
    "\n",
    "\n",
    "# criterion = DiceLoss()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# # apply adam\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# #apply sgd\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# apply a learning rate scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3, verbose=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_class_iou(pred, target, num_classes):\n",
    "#     iou_list = []\n",
    "#     pred = pred.view(-1)\n",
    "#     target = target.view(-1)\n",
    "\n",
    "#     for cls in range(num_classes):\n",
    "#         pred_inds = pred == cls\n",
    "#         target_inds = target == cls\n",
    "#         intersection = (pred_inds & target_inds).sum().float().item()\n",
    "#         union = (pred_inds | target_inds).sum().float().item()\n",
    "#         if union == 0:\n",
    "#             iou_list.append(float('nan')) \n",
    "#         else:\n",
    "#             iou_list.append(intersection / union)\n",
    "\n",
    "#     return torch.tensor(iou_list, device=pred.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 52/52 [00:42<00:00,  1.21batch/s, loss=0.888]\n",
      "Epoch 2/10: 100%|██████████| 52/52 [00:42<00:00,  1.22batch/s, loss=0.46]  \n",
      "Epoch 3/10: 100%|██████████| 52/52 [00:42<00:00,  1.21batch/s, loss=0.416] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 52/52 [00:42<00:00,  1.21batch/s, loss=0.406] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 52/52 [00:42<00:00,  1.21batch/s, loss=0.386] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaler = GradScaler()\n",
    "import logging\n",
    "\n",
    "# apply logging to record the training result\n",
    "logging.basicConfig(filename='training12.log', level=logging.INFO)\n",
    "\n",
    "early_stopping = EarlyStopping(patience=3, verbose=True) \n",
    "\n",
    "num_epochs = 10  \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    \n",
    "    with tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\") as pbar:\n",
    "        for images, masks in train_loader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)['out']\n",
    "            loss = criterion(outputs, masks.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            pbar.set_postfix(loss=running_loss / len(train_loader))\n",
    "            pbar.update(1)\n",
    "\n",
    "    logging.info(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
    "\n",
    "     # evaluate model\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_class_ious = []\n",
    "    with torch.no_grad():\n",
    "        for images, masks in val_loader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            outputs = model(images)['out']\n",
    "            loss = criterion(outputs, masks)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            iou_scores = iou_metric(preds, masks)\n",
    "            val_class_ious.append(iou_scores.cpu().numpy())\n",
    "\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_class_ious = np.nanmean(val_class_ious, axis=0)\n",
    "    mean_iou = np.nanmean(val_class_ious)\n",
    "\n",
    "    logging.info(f'Validation Loss: {val_loss:.4f}')\n",
    "    for i, iou in enumerate(val_class_ious):\n",
    "        logging.info(f'{class_names[i]} IoU: {iou:.4f}')\n",
    "    logging.info(f'Mean IoU: {mean_iou:.4f}')\n",
    "\n",
    "    \n",
    "    # mean_iou = np.nanmean(val_class_ious)\n",
    "    early_stopping(mean_iou, model)\n",
    "    if early_stopping.early_stop:\n",
    "        logging.info(\"Early stopping\")\n",
    "        break\n",
    "    scheduler.step(mean_iou)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    \n",
    "\n",
    "# load best model\n",
    "model.load_state_dict(torch.load('checkpoint.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate test IoU\n",
    "model.eval()\n",
    "test_class_ious = []\n",
    "with torch.no_grad():\n",
    "    for images, masks in test_loader:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        outputs = model(images)['out']\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        iou_scores = iou_metric(preds, masks)\n",
    "        test_class_ious.append(iou_scores.cpu().numpy())\n",
    "\n",
    "test_class_ious = np.nanmean(test_class_ious, axis=0)\n",
    "mean_test_iou = np.nanmean(test_class_ious)\n",
    "\n",
    "for i, iou in enumerate(test_class_ious):\n",
    "    logging.info(f'{class_names[i]} Test IoU: {iou:.4f}')\n",
    "logging.info(f'Mean IoU: {mean_test_iou:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'trained_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
